{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie reviews\n",
    "\n",
    "This notebook takes you though a complete iteration of Machine Learning Assignment 1 - Movie reviews. The assignment details (including links to download the data) can be found [here](https://docs.google.com/document/d/1WGYw99e5q6j5V0Zrf2HveagU6URt_kVvdR8B9HYQ99E/edit?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    movie_data = pd.read_csv(fn, sep='\\t')\n",
    "    print(\"movie_data is:\", type(movie_data))\n",
    "    print(\"movie_data has\", movie_data.shape[0], \"rows and\", movie_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in movie_data:\")\n",
    "    print(movie_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in movie_data:\")\n",
    "    print(movie_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'good' movie reviews in the dataset: \")\n",
    "        print(movie_data['sentiment'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        hv = HashingVectorizer(n_features=2 ** 17, alternate_sign=False)\n",
    "        X_hv = hv.fit_transform(movie_data.review)\n",
    "        fitted_transformations.append(hv)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    else: # transform() \n",
    "        X_hv = fitted_transformations[0].transform(movie_data.review)\n",
    "        print(\"Shape of HashingVectorizer X:\")\n",
    "        print(X_hv.shape)\n",
    "    \n",
    "\n",
    "        # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        #Tricia is a good girl in Indonesia\n",
    "        #Leffin is a good boy in India\n",
    "        #n_features = 2 ** 3 = 000,001,010,011,100,101,110,111\n",
    "        #hash = algorithm that converts anything to numbers - encryption, no personalized dictionary\n",
    "        #2**3 = faster to run = more collision  / 2**20 = longer to run = lesser collision\n",
    "        #2**17 = good base\n",
    "        \n",
    "        #countVectorizer = final output is a number, not using a bag of words, it has a dictionary and it is fine because we have a set number of reviews\n",
    "        #not good = bag of words, hashing vectorizer would not be able to detect it\n",
    "        #ngram_range = 1,2 = Tricia, is , Tricia is\n",
    "        #maximum number is high = takes longer to run\n",
    "        #strip_accents = remove accents\n",
    "        #ascii : dictionary of characters\n",
    "        #tokenizer: looking is look, looks is look\n",
    "        #remove stop_words {english}\n",
    "        #max_features: limit the features\n",
    "        cv = CountVectorizer(ngram_range=(1,3), stop_words='english', strip_accents='ascii')\n",
    "        X_cv = cv.fit_transform(movie_data.review)\n",
    "        fitted_transformations.append(cv)\n",
    "        print(\"Shape of CountVectorizer X:\")\n",
    "        print(X_cv.shape)\n",
    "    else: # transform() \n",
    "        X_cv = fitted_transformations[0].transform(movie_data.review)\n",
    "        print(\"Shape of CountVectorizer X:\")\n",
    "        print(X_cv.shape)\n",
    "        \n",
    "        #strip_accents : {'ascii'}\n",
    "\n",
    "        \n",
    "        \n",
    "   # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_cv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_cv)\n",
    "    \n",
    "     #create additional quantitative features\n",
    "     #features from Amazon.csv to add to feature set\n",
    "    movie_data['word_count'] = movie_data['review'].str.split(' ').str.len()\n",
    "    movie_data['punc_count'] = movie_data['review'].str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = movie_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "     #feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = movie_data['sentiment']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(movie_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, movie_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sets from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "movie_data has 25000 rows and 3 columns \n",
      "\n",
      "the data types for each of the columns in movie_data:\n",
      "id           object\n",
      "sentiment     int64\n",
      "review       object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in movie_data:\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
      "The rate of 'good' movie reviews in the dataset: \n",
      "0.5\n",
      "Shape of HashingVectorizer X:\n",
      "(25000, 131072)\n",
      "Shape of CountVectorizer X:\n",
      "(25000, 4302235)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0         433          20\n",
      "1         158          16\n",
      "2         378          20\n",
      "3         379           8\n",
      "4         367           9\n",
      "5          89           5\n",
      "6         112           9\n",
      "7         132           9\n",
      "8         163           7\n",
      "9          43           5\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(25000, 4302237)\n",
      "(25000, 4302237)\n",
      "Shape of X_train and X_test:\n",
      "(20000, 4302237)\n",
      "(5000, 4302237)\n",
      "Shape of y_train and y_test:\n",
      "(20000,)\n",
      "(5000,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(20000, 5)\n",
      "(5000, 5)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "# OK CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='/users/kinetic.tricia/moviereviews_train.tsv', my_random_seed=49)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (and tune) Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10009, 'Neg': 9991, 'TP': 4047, 'TN': 6185, 'FP': 3806, 'FN': 5962, 'Accuracy': 0.5116, 'Precision': 0.5153444543486566, 'Recall': 0.404336097512239, 'desc': 'ols_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "ols = linear_model.SGDClassifier(loss=\"squared_loss\")\n",
    "ols.fit(X_train, y_train)\n",
    "\n",
    "ols_performance_train = BinaryClassificationPerformance(ols.predict(X_train), y_train, 'ols_train')\n",
    "ols_performance_train.compute_measures()\n",
    "print(ols_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10009, 'Neg': 9991, 'TP': 10009, 'TN': 9991, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'svm_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, 'svm_train')\n",
    "svm_performance_train.compute_measures()\n",
    "print(svm_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10009, 'Neg': 9991, 'TP': 10009, 'TN': 9991, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'lgs_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log')\n",
    "lgs.fit(X_train, y_train)\n",
    "\n",
    "lgs_performance_train = BinaryClassificationPerformance(lgs.predict(X_train), y_train, 'lgs_train')\n",
    "lgs_performance_train.compute_measures()\n",
    "print(lgs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10009, 'Neg': 9991, 'TP': 10009, 'TN': 9991, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'nbs_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X_train, y_train)\n",
    "\n",
    "nbs_performance_train = BinaryClassificationPerformance(nbs.predict(X_train), y_train, 'nbs_train')\n",
    "nbs_performance_train.compute_measures()\n",
    "print(nbs_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10009, 'Neg': 9991, 'TP': 10009, 'TN': 9991, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'prc_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X_train, y_train)\n",
    "\n",
    "prc_performance_train = BinaryClassificationPerformance(prc.predict(X_train), y_train, 'prc_train')\n",
    "prc_performance_train.compute_measures()\n",
    "print(prc_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10009, 'Neg': 9991, 'TP': 10009, 'TN': 9991, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'rdg_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "rdg.fit(X_train, y_train)\n",
    "\n",
    "rdg_performance_train = BinaryClassificationPerformance(rdg.predict(X_train), y_train, 'rdg_train')\n",
    "rdg_performance_train.compute_measures()\n",
    "print(rdg_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10009, 'Neg': 9991, 'TP': 8634, 'TN': 5057, 'FP': 4934, 'FN': 1375, 'Accuracy': 0.68455, 'Precision': 0.6363502358490566, 'Recall': 0.8626236387251474, 'desc': 'rdf_train'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rdf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rdf.fit(X_train, y_train)\n",
    "\n",
    "rdf_performance_train = BinaryClassificationPerformance(rdf.predict(X_train), y_train, 'rdf_train')\n",
    "rdf_performance_train.compute_measures()\n",
    "print(rdf_performance_train.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fits = [ols_performance_train, svm_performance_train, lgs_performance_train, nbs_performance_train, prc_performance_train, rdg_performance_train, rdf_performance_train]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at reviews based on their classification\n",
    "\n",
    "Let's say we decide that Ordinary Least Squares (OLS) Regression is the best model for generalization. Let's take a look at some of the reviews and try to make a (subjective) determination of whether it's generalizing well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_predictions = ols.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at some false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(ols_predictions)):\n",
    "    if (ols_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['sentiment'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['review'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">WARNING: Don't look at test set performance too much!</span>\n",
    "\n",
    "---\n",
    "\n",
    "The following cells show performance on your test set. Do not look at this too often! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: ordinary least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_performance_test = BinaryClassificationPerformance(ols.predict(X_test), y_test, 'ols_test')\n",
    "ols_performance_test.compute_measures()\n",
    "print(ols_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, 'svm_test')\n",
    "svm_performance_test.compute_measures()\n",
    "print(svm_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgs_performance_test = BinaryClassificationPerformance(lgs.predict(X_test), y_test, 'lgs_test')\n",
    "lgs_performance_test.compute_measures()\n",
    "print(lgs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_performance_test = BinaryClassificationPerformance(nbs.predict(X_test), y_test, 'nbs_test')\n",
    "nbs_performance_test.compute_measures()\n",
    "print(nbs_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(X_test), y_test, 'prc_test')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdg_performance_test = BinaryClassificationPerformance(rdg.predict(X_test), y_test, 'rdg_test')\n",
    "rdg_performance_test.compute_measures()\n",
    "print(rdg_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_performance_test = BinaryClassificationPerformance(rdf.predict(X_test), y_test, 'rdf_test')\n",
    "rdf_performance_test.compute_measures()\n",
    "print(rdf_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = [ols_performance_test, svm_performance_test, lgs_performance_test, nbs_performance_test, prc_performance_test, rdg_performance_test, rdf_performance_test]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in test data for submission\n",
    "# OK CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = process_raw_data(fn='/users/kinetic.tricia/moviereviews_test.tsv', my_random_seed=49, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 25,000): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a <span style=\"color:red\">*single*</span> model for your submission. In this code, I am choosing the Ordinary Least Squares model fit, which is in the `ols` object. But you should choose the model that is performing the best for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = ols.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('/users/kinetic.tricia/moviereviews_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
